{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from textblob import TextBlob, Word\n",
    "import nltk\n",
    "df = pd.read_csv('Student_combined_dataset.csv',sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Polarity'] = df['Speech'].apply(lambda x: TextBlob(x).sentiment[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Sentiment'] = df['Polarity'].apply(lambda n: 1 if n >= 0.05 else (0 if n <= 0.05  else -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\divya\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\divya\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\divya\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import text2emotion as te\n",
    "def text_2_emotions(text):\n",
    "    result = te.get_emotion(text)\n",
    "    return result\n",
    "res = [text_2_emotions(df['Speech'][asp]) for asp in range(len(df))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['emotions'] = res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import text2emotion as te\n",
    "import numpy as np\n",
    "def text_2_emotions(text):\n",
    "    r = []\n",
    "    result = te.get_emotion(text)\n",
    "    for k,v in result.items(): \n",
    "        if result[k] != 0.0:\n",
    "            r.append(max(result, key=result.get))\n",
    "    return np.unique(r)\n",
    "res = [text_2_emotions(df['Speech'][asp]) for asp in range(len(df))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['M_emotions'] = res\n",
    "df.to_csv('student_emotions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('student_emotions.csv')\n",
    "import nltk\n",
    "import string\n",
    "df = df.drop(['Unnamed: 0','Unnamed: 0.1'],axis=1)\n",
    "def remove_punctuations(text):\n",
    "    for punctuation in string.punctuation:\n",
    "        text = text.replace(punctuation, '')\n",
    "    return text\n",
    "\n",
    "df['Speech'] = df['Speech'].apply(remove_punctuations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pattern 9 # Adjective  + Verb + Noun \n",
    "def aspect_AjVN(txt):\n",
    "    #JJ adjective\n",
    "    #JJR adjective, comparative \n",
    "    #JJS adjective, superlative \n",
    "\n",
    "    sentList = nltk.sent_tokenize(txt) # Splitting the text into sentences\n",
    "    #print(sentList)\n",
    "    for line in sentList:\n",
    "        new_txt_list = nltk.word_tokenize(line)\n",
    "        taggedList = nltk.pos_tag(new_txt_list)\n",
    "\n",
    "    #print(taggedList)\n",
    "    categoryList = []\n",
    "\n",
    "    for i in range(0,len(taggedList)-2):\n",
    "        if((taggedList[i][1]==\"JJ\" or taggedList[i][1]==\"JJS\" or taggedList[i][1]==\"JJR\") and\n",
    "           (taggedList[i+1][1]==\"VB\" or taggedList[i+1][1]==\"VBP\" or taggedList[i+1][1]==\"VBG\" or taggedList[i+1][1]==\"VBN\" or taggedList[i+1][1]==\"VBD\") and\n",
    "           (taggedList[i+2][1]==\"NN\" or taggedList[i+2][1]==\"NNS\" or taggedList[i+2][1]==\"NNP\" or taggedList[i+2][1]==\"NNPS\")):\n",
    "\n",
    "            categoryList.append([taggedList[i][0]+\" \"+taggedList[i+1][0]+\" \"+taggedList[i+2][0]])\n",
    "\n",
    "    return categoryList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "categoryList_AjVN = [aspect_AjVN(df['Speech'][unt]) for unt in range(0,len(df))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['many errorrated feedbacks']],\n",
       " [['cleaner looking Oh']],\n",
       " [['youre saying number'], ['dont do anything']],\n",
       " [['ta remember Displaying'],\n",
       "  ['havent put anything'],\n",
       "  ['dont put pseudocomments']],\n",
       " [['best played song'], ['yall playing crosstalk']],\n",
       " [],\n",
       " [],\n",
       " [['other remaining half'], ['lower remaining half']],\n",
       " [['wouldnt make sense']],\n",
       " [],\n",
       " [],\n",
       " [['doesnt make sense'],\n",
       "  ['youre comparing Okay'],\n",
       "  ['theyre explaining crosstalk']],\n",
       " [],\n",
       " [['mine doing equals']],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [['best looking array'],\n",
       "  ['Good go man'],\n",
       "  ['Binary searching doesnt'],\n",
       "  ['other tabs RAM'],\n",
       "  ['many fucking bitches']],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [['dont think thats']],\n",
       " [['wouldnt be Sorry']],\n",
       " [['itd be character']],\n",
       " [['shit done No'],\n",
       "  ['teamwork Fucking shit'],\n",
       "  ['shit dude Ridiculous'],\n",
       "  ['random shuffling Randomly'],\n",
       "  ['dead lifting something'],\n",
       "  ['wild loop crosstalk']],\n",
       " [['real laughing Hes']],\n",
       " [['key equal So'],\n",
       "  ['didnt understand Okay'],\n",
       "  ['youre doing C'],\n",
       "  ['yours printing crosstalk'],\n",
       "  ['yall got Smoothie']],\n",
       " [['good shit Yeah']]]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categoryList_AjVN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Iterable\n",
    "def nested_list_flatten(lis):\n",
    "     for item in lis:\n",
    "            if isinstance(item, Iterable) and not isinstance(item, str):\n",
    "                for x in nested_list_flatten(item):\n",
    "                    yield x\n",
    "            else:        \n",
    "                    yield item\n",
    "flat_AjVN= list(nested_list_flatten(categoryList_AjVN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "counter=Counter(flat_AjVN)\n",
    "# split dictionary into keys and values\n",
    "keys = []\n",
    "values = []\n",
    "items = counter.items()\n",
    "for item in items:\n",
    "    keys.append(item[0]), values.append(item[1])\n",
    "data = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['aspects'] = keys\n",
    "data['frequency'] = values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "import text2emotion as te\n",
    "import numpy as np\n",
    "def text_2_emotions(text):\n",
    "    r = []\n",
    "    result = te.get_emotion(text)\n",
    "    for k,v in result.items(): \n",
    "        if result[k] != 0.0:\n",
    "            r.append(max(result, key=result.get))\n",
    "    return np.unique(r)\n",
    "res = []\n",
    "for asp in keys:\n",
    "    res.append(text_2_emotions(str(asp)))\n",
    "data['emotions'] = res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('aspect_AjVN_emotion.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pATTERN 10  Adjective  + Adverb\n",
    "def aspect_AjA(txt):\n",
    "    #JJ adjective\n",
    "    #JJR adjective, comparative \n",
    "    #JJS adjective, superlative \n",
    "\n",
    "    sentList = nltk.sent_tokenize(txt) # Splitting the text into sentences\n",
    "\n",
    "    for line in sentList:\n",
    "        new_txt_list = nltk.word_tokenize(line)\n",
    "        taggedList = nltk.pos_tag(new_txt_list)\n",
    "\n",
    "    #print(taggedList)\n",
    "    categoryList = []\n",
    "\n",
    "    for i in range(0,len(taggedList)-1):\n",
    "        if((taggedList[i][1]==\"JJ\" or taggedList[i][1]==\"JJS\" or taggedList[i][1]==\"JJR\") and \n",
    "           (taggedList[i+1][1]==\"RB\" or taggedList[i+1][1]==\"RBR\" or taggedList[i+1][1]==\"RBS\")):\n",
    "\n",
    "            categoryList.append([taggedList[i][0]+\" \"+taggedList[i+1][0]])\n",
    "\n",
    "    return categoryList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "categoryList_AjA = [aspect_AjA(df['Speech'][unt]) for unt in range(0,len(df))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_AjA = list(nested_list_flatten(categoryList_AjA))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter=Counter(flat_AjA)\n",
    "keys = []\n",
    "values = []\n",
    "items = counter.items()\n",
    "for item in items:\n",
    "    keys.append(item[0]), values.append(item[1])\n",
    "data = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['aspects'] = keys\n",
    "data['frequency'] = values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = []\n",
    "for asp in keys:\n",
    "    res.append(text_2_emotions(str(asp)))\n",
    "data['emotions'] = res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('aspect_AjA_emotion.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Pattern 14 Adverb + Adjective  + Noun \n",
    "def aspect_AdAN(txt):\n",
    "    #JJ adjective\n",
    "    #JJR adjective, comparative \n",
    "    #JJS adjective, superlative \n",
    "\n",
    "    sentList = nltk.sent_tokenize(txt) # Splitting the text into sentences\n",
    "\n",
    "    for line in sentList:\n",
    "        new_txt_list = nltk.word_tokenize(line)\n",
    "        taggedList = nltk.pos_tag(new_txt_list)\n",
    "\n",
    "    #print(taggedList)\n",
    "    categoryList = []\n",
    "\n",
    "    for i in range(0,len(taggedList)-2):\n",
    "        if((taggedList[i][1]==\"RB\" or taggedList[i][1]==\"RBR\" or taggedList[i][1]==\"RBS\") and\n",
    "           (taggedList[i+1][1]==\"JJ\" or taggedList[i+1][1]==\"JJS\" or taggedList[i+1][1]==\"JJR\") and \n",
    "          (taggedList[i+2][1]==\"NN\" or taggedList[i+2][1]==\"NNS\" or taggedList[i+2][1]==\"NNP\" or taggedList[i+2][1]==\"NNPS\")):\n",
    "\n",
    "            categoryList.append([taggedList[i][0]+\" \"+taggedList[i+1][0]+\" \"+taggedList[i+2][0]])\n",
    "\n",
    "    return categoryList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "categoryList_AdAN = [aspect_AdAN(df['Speech'][unt]) for unt in range(0,len(df))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_AdAN = list(nested_list_flatten(categoryList_AdAN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter=Counter(flat_AdAN)\n",
    "keys = []\n",
    "values = []\n",
    "items = counter.items()\n",
    "for item in items:\n",
    "    keys.append(item[0]), values.append(item[1])\n",
    "data = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['aspects'] = keys\n",
    "data['frequency'] = values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = []\n",
    "for asp in keys:\n",
    "    res.append(text_2_emotions(str(asp)))\n",
    "data['emotions'] = res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('aspect_AdAN_emotion.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
