{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Aspect_extraction_speech_sent.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMnjVemfS3PPvTEDotu0rgf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dhivyapm/NLP/blob/main/Aspect_extraction_speech_sent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 435
        },
        "id": "RZXqtrtOMHMF",
        "outputId": "74f0c972-df5b-47e5-9a12-260efd0f3e74"
      },
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from textblob import TextBlob\n",
        "namess= ['Speech']\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/dhivyapm/NLP/main/ID%2011-%20Complete.csv',header = None, names= namess)\n",
        "df"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Speech</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>28th.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Max [inaudible 00:00:23].</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>That basically just goes through and if no nu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>I get it.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>211</th>\n",
              "      <td>Oh the 2223 class?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>212</th>\n",
              "      <td>Oh, you guys are taking a different one than I...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>213</th>\n",
              "      <td>I'm in 2223.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>214</th>\n",
              "      <td>All right, I think I'm done.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>215</th>\n",
              "      <td>Yeah.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>216 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                Speech\n",
              "0                                                28th.\n",
              "1                                                   11\n",
              "2                            Max [inaudible 00:00:23].\n",
              "3     That basically just goes through and if no nu...\n",
              "4                                            I get it.\n",
              "..                                                 ...\n",
              "211                                 Oh the 2223 class?\n",
              "212  Oh, you guys are taking a different one than I...\n",
              "213                                      I'm in 2223. \n",
              "214                      All right, I think I'm done. \n",
              "215                                             Yeah. \n",
              "\n",
              "[216 rows x 1 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K23KwpkUPImg",
        "outputId": "dff265c2-885e-4c51-f6cd-6cc47be4fe5a"
      },
      "source": [
        "import string\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "#converting the reviews to lowercase\n",
        "df['Speech'] = df['Speech'].apply(str.lower)\n",
        "df['Speech'] = df['Speech'].str.replace('[{}]'.format(string.punctuation), '')\n",
        "df['Speech'] = df['Speech'].str.replace('[{}]'.format(string.digits), '')\n",
        "rem = ['Hoel','crosstalk','inaudible','affirmative','singing','laughing']\n",
        "df['clean_Speech'] = df.apply(lambda row: nltk.word_tokenize(row['Speech']), axis=1)\n",
        "df['clean_Speech'] = df.apply(lambda row: [t for t in row['clean_Speech'] if t not in rem], axis=1)\n",
        "df['Pos_Tag'] = df.apply(lambda row: nltk.pos_tag(row['clean_Speech']), axis=1)"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_DZgvtJSMZxn"
      },
      "source": [
        "\n",
        "# pATTERN 10  Adjective  + Adverb\n",
        "def aspect_AjA(df):\n",
        "\n",
        "\n",
        "    #print(taggedList)\n",
        "    categoryList = []\n",
        "\n",
        "    for i in range(0,len(df)-1):\n",
        "        if((df[i][1]==\"JJ\" or df[i][1]==\"JJS\" or df[i][1]==\"JJR\") and \n",
        "           (df[i+1][1]==\"RB\" or df[i+1][1]==\"RBR\" or df[i+1][1]==\"RBS\")):\n",
        "\n",
        "            categoryList.append([df[i][0]+\" \"+df[i+1][0]])\n",
        "\n",
        "    return categoryList"
      ],
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H0pTUmSirYFe"
      },
      "source": [
        "# Pattern 14 Adverb + Adjective  + Noun \n",
        "def aspect_AdAN(txt):\n",
        "    \n",
        "    categoryList = []\n",
        "\n",
        "    for i in range(0,len(txt)-2):\n",
        "        if((txt[i][1]==\"RB\" or txt[i][1]==\"RBR\" or txt[i][1]==\"RBS\") and\n",
        "           (txt[i+1][1]==\"JJ\" or txt[i+1][1]==\"JJS\" or txt[i+1][1]==\"JJR\") and \n",
        "          (txt[i+2][1]==\"NN\" or txt[i+2][1]==\"NNS\" or txt[i+2][1]==\"NNP\" or txt[i+2][1]==\"NNPS\")):\n",
        "\n",
        "            categoryList.append([txt[i][0]+\" \"+txt[i+1][0]+\" \"+txt[i+2][0]])\n",
        "\n",
        "    return categoryList"
      ],
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQJzA8-POE49"
      },
      "source": [
        "categoryList_AdAN = [aspect_AdAN(df['Pos_Tag'][unt]) for unt in range(0,len(df))]"
      ],
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "haxX_eRBRCX4"
      },
      "source": [
        "cat = pd.DataFrame(categoryList_AdAN)\n",
        "cat.to_csv('aspects_11.csv')"
      ],
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cB-nEKVJYWfC",
        "outputId": "8ba16ed4-6a5b-49ea-db9a-8b3398ecd2b5"
      },
      "source": [
        "import text2emotion as te\n",
        "text = 'so i dont'\n",
        "result = te.get_emotion(text)\n",
        "result"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Angry': 0, 'Fear': 0, 'Happy': 0, 'Sad': 0, 'Surprise': 0}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G1A9k_XPZl1O",
        "outputId": "6c98b056-d27f-44a1-d1e1-7a7a7cefa952"
      },
      "source": [
        "pip install text2emotion"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting text2emotion\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fe/31/b190e37c1396ca68ab1b5c8ea1a23f2f7848df532ad69133e94853120aed/text2emotion-0.0.5-py3-none-any.whl (57kB)\n",
            "\r\u001b[K     |█████▊                          | 10kB 11.4MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 20kB 15.9MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 30kB 9.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 40kB 8.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 51kB 5.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 61kB 2.9MB/s \n",
            "\u001b[?25hCollecting emoji>=0.6.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/24/fa/b3368f41b95a286f8d300e323449ab4e86b85334c2e0b477e94422b8ed0f/emoji-1.2.0-py3-none-any.whl (131kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 7.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from text2emotion) (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk->text2emotion) (1.15.0)\n",
            "Installing collected packages: emoji, text2emotion\n",
            "Successfully installed emoji-1.2.0 text2emotion-0.0.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qPk68TCuZpPw"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}